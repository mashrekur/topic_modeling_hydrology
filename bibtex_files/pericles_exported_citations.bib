@article{doi:10.1029/2020WR027251,
author = {Ombadi, M. and Nguyen, P. and Sorooshian, S. and Hsu, K.},
title = {Evaluation of methods for causal discovery in hydrometeorological systems},
journal = {Water Resources Research},
volume = {n/a},
number = {n/a},
pages = {e2020WR027251},
keywords = {Causality, Empirical Data Mining, Systems Identification, Prediction, Evapotranspiration, Causal Inference},
doi = {10.1029/2020WR027251},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020WR027251},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2020WR027251},
note = {e2020WR027251 2020WR027251},
abstract = {Key Points: A brief description of the fundamentals and assumptions of four causal discovery methods is provided. The methods’ performance and their sensitivity to sample length and presence of noise is assessed using synthetic data from a hydrologic model. Causal analysis is applied to examine and formulate hypotheses on the significance of environmental drivers of evapotranspiration.}
}
@article{doi:10.1029/2019WR024908,
author = {Tennant, Christopher and Larsen, Laurel and Bellugi, Dino and Moges, Edom and Zhang, Liang and Ma, Hongxu},
title = {The utility of information flow in formulating discharge forecast models: a case study from an arid snow-dominated catchment},
journal = {Water Resources Research},
volume = {n/a},
number = {n/a},
pages = {e2019WR024908},
keywords = {Hydrologic forecasting, information theory, machine learning, watershed, snowmelt},
doi = {10.1029/2019WR024908},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024908},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024908},
note = {e2019WR024908 2019WR024908},
abstract = {Abstract Streamflow forecasts often perform poorly because of improper representation of hydrologic response timescales in underlying models. Here, we use transfer entropy (TE), which measures information-flow between variables, to identify dominant drivers of discharge and their timescales using sensor data from the Dry Creek Experimental Watershed, ID, USA. Consistent with previous mechanistic studies, TE revealed that snowpack accumulation and partitioning into melt, recharge, and evaporative loss dominated discharge patterns and that snow-sourced baseflow reduced the greatest amount of uncertainty in discharge. We hypothesized that machine learning models (MLMs) specified in accordance with the dominant lag timescales, identified via TE, would outperform timescale-agnostic models. However, while lagged-variable random forest regressions captured the dominant process—seasonal snowmelt—they ultimately did not perform as well as the unlagged models, provided those models were specified with input data aggregated over a range of timescales. Unlagged models, not constrained by timescales of the dominant processes, more effectively represented variable interactions (e.g., rain-on-snow events) playing a critical role in translating precipitation into streamflow over long, intermediate, and short timescales. Meanwhile, long-short-term-memory (LSTM) models were effective in internally identifying the key lag and aggregation scales for predicting discharge. Parsimonious specification of LSTM models, using only daily unlagged precipitation and temperature data produced the highest-performing predictions. Our findings suggest that TE can identify dominant streamflow controls and the relative importance of different mechanisms of streamflow generation, useful for establishing process baselines and fingerprinting watersheds. However, restricting MLMs based on dominant timescales undercuts their skill at learning these timescales internally.}
}
@article{doi:10.1029/2019WR025924,
author = {Schmidt, Lennart and Heße, Falk and Attinger, Sabine and Kumar, Rohini},
title = {Challenges in Applying Machine Learning Models for Hydrological Inference: A Case Study for Flooding Events Across Germany},
journal = {Water Resources Research},
volume = {56},
number = {5},
pages = {e2019WR025924},
keywords = {machine learning, inference, floods},
doi = {10.1029/2019WR025924},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR025924},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR025924},
note = {e2019WR025924 10.1029/2019WR025924},
abstract = {Abstract Machine learning (ML) algorithms are being increasingly used in Earth and Environmental modeling studies owing to the ever-increasing availability of diverse data sets and computational resources as well as advancement in ML algorithms. Despite advances in their predictive accuracy, the usefulness of ML algorithms for inference remains elusive. In this study, we employ two popular ML algorithms, artificial neural networks and random forest, to analyze a large data set of flood events across Germany with the goals to analyze their predictive accuracy and their usability to provide insights to hydrologic system functioning. The results of the ML algorithms are contrasted against a parametric approach based on multiple linear regression. For analysis, we employ a model-agnostic framework named Permuted Feature Importance to derive the influence of models' predictors. This allows us to compare the results of different algorithms for the first time in the context of hydrology. Our main findings are that (1) the ML models achieve higher prediction accuracy than linear regression, (2) the results reflect basic hydrological principles, but (3) further inference is hindered by the heterogeneity of results across algorithms. Thus, we conclude that the problem of equifinality as known from classical hydrological modeling also exists for ML and severely hampers its potential for inference. To account for the observed problems, we propose that when employing ML for inference, this should be made by using multiple algorithms and multiple methods, of which the latter should be embedded in a cross-validation routine.},
year = {2020}
}
@article{doi:10.1029/2019WR025812,
author = {Bolorinos, Jose and Ajami, Newsha K. and Rajagopal, Ram},
title = {Consumption Change Detection for Urban Planning: Monitoring and Segmenting Water Customers During Drought},
journal = {Water Resources Research},
volume = {56},
number = {3},
pages = {e2019WR025812},
keywords = {demand management, drought management, water conservation},
doi = {10.1029/2019WR025812},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR025812},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR025812},
note = {e2019WR025812 10.1029/2019WR025812},
abstract = {Abstract Demand management is a powerful way for water utilities to address the challenges of population growth and climate change. Although active conservation efforts have been studied extensively, recent evidence suggests households respond to many external events beyond a utility's control, including political responses to extreme climatic episodes and corresponding mass media coverage. Despite their importance, these external factors are difficult to analyze in a controlled setting, and few tools exist to evaluate their influence on customers. Here, we present a consumption change detection (CCD) method that offers new insights into how climate-related mass media and policy events affect conservation by pinpointing the timing and magnitude of customer-level water use shifts. We use CCD to monitor and segment the responses of residential water customers to policy and media events in Costa Mesa, California, during the severe 2012–2016 drought. Our results show consumption reductions among 75\% of customers. Of these, 80\% reduced water use before mandatory restrictions were imposed, coincident with intensifying state policy responses and spikes in media coverage that affected all customer types during 2014. Analysis of standardized drought consumption trajectories indicates that 16\% of conserving customers increased consumption in 2015–2016. Conservation and rebound were both more likely among affluent and educated customers, suggesting that CCD can identify engaged and informed water savers who make suitable targets for water-efficient retrofit incentive schemes. This study demonstrates CCD's potential as a novel demand analysis tool in an interconnected world where external social, political, and climatic stressors can exert an important influence on customer behavior.},
year = {2020}
}
@article{doi:10.1029/2019WR025326,
author = {Xiang, Zhongrun and Yan, Jun and Demir, Ibrahim},
title = {A Rainfall-Runoff Model With LSTM-Based Sequence-to-Sequence Learning},
journal = {Water Resources Research},
volume = {56},
number = {1},
pages = {e2019WR025326},
keywords = {rainfall-runoff model, LSTM, machine learning, flood forecast, sequence learning, hydrology modeling},
doi = {10.1029/2019WR025326},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR025326},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR025326},
note = {e2019WR025326 2019WR025326},
abstract = {Abstract Rainfall-runoff modeling is a complex nonlinear time series problem. While there is still room for improvement, researchers have been developing physical and machine learning models for decades to predict runoff using rainfall data sets. With the advancement of computational hardware resources and algorithms, deep learning methods such as the long short-term memory (LSTM) model and sequence-to-sequence (seq2seq) modeling have shown a good deal of promise in dealing with time series problems by considering long-term dependencies and multiple outputs. This study presents an application of a prediction model based on LSTM and the seq2seq structure to estimate hourly rainfall-runoff. Focusing on two Midwestern watersheds, namely, Clear Creek and Upper Wapsipinicon River in Iowa, these models were used to predict hourly runoff for a 24-hr period using rainfall observation, rainfall forecast, runoff observation, and empirical monthly evapotranspiration data from all stations in these two watersheds. The models were evaluated using the Nash-Sutcliffe efficiency coefficient, the correlation coefficient, statistical bias, and the normalized root-mean-square error. The results show that the LSTM-seq2seq model outperforms linear regression, Lasso regression, Ridge regression, support vector regression, Gaussian processes regression, and LSTM in all stations from these two watersheds. The LSTM-seq2seq model shows sufficient predictive power and could be used to improve forecast accuracy in short-term flood forecast applications. In addition, the seq2seq method was demonstrated to be an effective method for time series predictions in hydrology.},
year = {2020}
}
@article{doi:10.1029/2018WR024558,
author = {Mewes, B. and Oppel, H. and Marx, V. and Hartmann, A.},
title = {Information-Based Machine Learning for Tracer Signature Prediction in Karstic Environments},
journal = {Water Resources Research},
volume = {56},
number = {2},
pages = {e2018WR024558},
keywords = {Machine learning, entropy, information content, karst, hydrograph separation},
doi = {10.1029/2018WR024558},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024558},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024558},
note = {e2018WR024558 2018WR024558},
abstract = {Abstract Karstic groundwater systems are often investigated by a combination of environmental or artificial tracers. One of the major downsides of tracer-based methods is the limited availability of tracer measurements, especially in data sparse regions. This study presents an approach to systematically evaluate the information content of the available data, to interpret predictions of tracer concentration from machine learning algorithms, and to compare different machine learning algorithms to obtain an objective assessment of their applicability for predicting environmental tracers. There is a large variety of machine learning approaches, but no clear rules exist on which of them to use for this specific problem. In this study, we formulated a framework to choose the appropriate algorithm for this purpose. We compared four different well-established machine learning algorithms (Support Vector Machines, Extreme Learning Machines, Decision Trees, and Artificial Neural Networks) in seven different karst springs in France for their capability to predict tracer concentrations, in this case SO42− and NO3−, from discharge. Our study reveals that the machine learning algorithms are able to predict some characteristics of the tracer concentration, but not the whole variance, which is caused by the limited information content in the discharge data. Nevertheless, discharge is often the only information available for a catchment, so the ability to predict at least some characteristics of the tracer concentrations from discharge time series to fill, for example, gaps or increase the database for consecutive analyses is a helpful application of machine learning in data sparse regions or for historic databases.},
year = {2020}
}
@article{doi:10.1029/2018WR024620,
author = {Konapala, Goutam and Mishra, Ashok},
title = {Quantifying Climate and Catchment Control on Hydrological Drought in the Continental United States},
journal = {Water Resources Research},
volume = {56},
number = {1},
pages = {e2018WR024620},
doi = {10.1029/2018WR024620},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024620},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024620},
note = {e2018WR024620 2018WR024620},
abstract = {Abstract The evolution of hydrological drought events is a result of complex (nonlinear) interactions between climate and catchment processes. To investigate such nonlinear relationship, we integrated a machine learning modeling framework based on the random forest (RF) algorithms with an interpretation framework to quantify the role of climate and catchment controls on hydrological drought. More particularly, our framework interprets a built RF machine-learning model to identify dominant variables and visualize their functional dependence and interaction effects on hydrological drought characteristics utilizing concepts of minimal depth, interactive depth, and partial dependence. We test our proposed modeling framework based on a set of 652 continental United States catchments with minimal human interference for a period of 1979–2010. Application of this framework indicated presence of three distinct drought regimes, which includes, Regime 1: droughts with longer duration, less frequent and lesser intensity; Regime 2: droughts with moderate duration, moderate frequency, and moderate intensity; and Regime 3: droughts with shorter duration, more frequent, and more intense. RF algorithm was able to accurately model the drought characteristics (intensity, duration, and number of events) for all the three drought regimes as a function of selected variables. It was observed that the type of dominant variables as well as their nonlinear functional relationship with hydrological droughts characteristics can vary between three selected regimes. Our interpretation framework indicated that catchment characteristics have a significant role in controlling the hydrologic drought for catchments (regime 1), whereas both climate and catchment characteristics control hydrological drought in regimes 2 and 3.},
year = {2020}
}
@article{doi:10.1029/2019WR024828,
author = {Avanzi, Francesco and Johnson, Ryan Curtis and Oroza, Carlos A. and Hirashima, Hiroyuki and Maurer, Tessa and Yamaguchi, Satoru},
title = {Insights Into Preferential Flow Snowpack Runoff Using Random Forest},
journal = {Water Resources Research},
volume = {55},
number = {12},
pages = {10727-10746},
keywords = {preferential flow, snow, Random Forest, lysimeters, SNOWPACK},
doi = {10.1029/2019WR024828},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024828},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024828},
note = { 10.1029/2019WR024828},
abstract = {Abstract Using 12 seasons of data from a multicompartment snow lysimeter and a statistical learning algorithm (Random Forest), we investigated to what extent preferential flow snowpack runoff can be predicted from concurrent weather and snow conditions, as well as the relative importance of factors affecting this process. We found that preferential flow development can be partially predicted based on concurrent weather and snow conditions. In this case study where snow is generally wet and coarse, the most important predictors of standard and maximum deviation from mean spatial snowpack runoff are related to weather inputs and their interaction with the snowpack (rainfall, longwave radiation, and snow-surface temperature) and to more season-specific snow properties (number of macroscopic snow layers and snowfall days to date, the latter being a feature we included to account for microstructural heterogeneity developing at smaller scales than macroscopic layers). This combination between weather and season-specific snow factors and the fact that several of these important features are correlated with other processes result in significant seasonal variability of the Random Forest algorithm's accuracy. All versions of the Random Forest algorithm underestimated seasonal peaks in preferential flow, which points to these peaks being either undersampled in our data set or caused by poorly understood redistribution processes acting at larger spatial scales than the size of our multicompartment lysimeter (e.g., dimples).},
year = {2019}
}
@article{doi:10.1029/2019WR024884,
author = {Shaeri Karimi, Sara and Saintilan, Neil and Wen, Li and Valavi, Roozbeh},
title = {Application of Machine Learning to Model Wetland Inundation Patterns Across a Large Semiarid Floodplain},
journal = {Water Resources Research},
volume = {55},
number = {11},
pages = {8765-8778},
keywords = {machine learning, downsampling, sensitivity-specificity sum maximizer, inundation regime, wetland, environmental water},
doi = {10.1029/2019WR024884},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024884},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024884},
note = { 2019WR024884},
abstract = {Abstract Inundation is a primary driver of floodplain ecology. Understanding temporal and spatial variability of inundation patterns is critical for optimum resource management, particularly in striking an appropriate balance between environmental water application and extractive use. Nevertheless, quantifying inundation at the fine resolution required of ecological modeling is an immense challenge in these environments. In this study, Random Forest, a machine learning technique, was implemented to predict the inundation pattern in a section of the Darling River Floodplain, Australia, at a spatial scale of 30 m and daily temporal resolution. The model achieved very good performance with an average accuracy of 0.915 based on the area under the receiver operating characteristic curve over 10 runs of the model in testing data sets. Six variables explained 70\% of the total contribution to inundation occurrence, with the most influential being landscape shape (local deviation from global mean elevation), elevation-weighted distance to the river, the magnitude of river flow (10- and 30-day accumulated river discharge), local rainfall, and soil moisture. This approach is applicable to other floodplains across the world where understanding of fine-scale inundation pattern is for operational ecological management and scenario testing.},
year = {2019}
}
@article{doi:10.1029/2019WR025820,
author = {Jiang, Peishi and Kumar, Praveen},
title = {Using Information Flow for Whole System Understanding From Component Dynamics},
journal = {Water Resources Research},
volume = {55},
number = {11},
pages = {8305-8329},
keywords = {information flow, causal history analysis, partial information decomposition, stream chemistry, weighted transitive reduction, long memory process},
doi = {10.1029/2019WR025820},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR025820},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR025820},
note = { 10.1029/2019WR025820},
abstract = {Abstract Complex systems that exhibit emergent behaviors arise as a result of nonlinear interdependencies among multiple components. Characterizing how such whole system dynamics are sustained through multivariate interaction remains an open question. In this study, we propose an information flow-based framework to investigate how the present state of any component arises as a result of the past interactions among interdependent variables, which is termed as causal history. Using a partitioning time lag, we divide this into immediate and distant causal history components and then characterize the information flow-based interactions within these as self- and cross-feedbacks. Such a partition allows us to characterize the information flow from the two feedbacks in both histories by using partial information decomposition as unique, synergistic, or redundant interactions. We employ this casual history analysis approach to investigate the information flows in a short-memory coupled logistic model and a long-memory observed stream chemistry dynamics. While the dynamics of the short-memory system are mainly maintained by its recent historical states, the current state of each stream solute is sustained by self-feedback-dominated recent dynamics and cross-dependency-dominated earlier dynamics. The analysis suggests that the observed 1/f signature of each solute is a result of the interactions with other variables in the stream. Based on high-density data streams, the approach developed here for investigating multivariate evolutionary dynamics provides an effective way to understand how components of dynamical system interact to create emergent whole system behavioral patterns such as long-memory dependency.},
year = {2019}
}
@article{doi:10.1029/2019WR024883,
author = {Ross, Matthew R. V. and Topp, Simon N. and Appling, Alison P. and Yang, Xiao and Kuhn, Catherine and Butman, David and Simard, Marc and Pavelsky, Tamlin M.},
title = {AquaSat: A Data Set to Enable Remote Sensing of Water Quality for Inland Waters},
journal = {Water Resources Research},
volume = {55},
number = {11},
pages = {10012-10025},
keywords = {remote sensing, water quality, big data, water clarity, data infrastructure},
doi = {10.1029/2019WR024883},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024883},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024883},
note = { 10.1029/2019WR024883},
abstract = {Abstract Satellite estimates of inland water quality have the potential to vastly expand our ability to observe and monitor the dynamics of large water bodies. For almost 50 years, we have been able to remotely sense key water quality constituents like total suspended sediment, dissolved organic carbon, chlorophyll a, and Secchi disk depth. Nonetheless, remote sensing of water quality is poorly integrated into inland water sciences, in part due to a lack of publicly available training data and a perception that remote estimates are unreliable. Remote sensing models of water quality can be improved by training and validation on larger data sets of coincident field and satellite observations, here called matchups. To facilitate model development and deeper integration of remote sensing into inland water science, we have built AquaSat, the largest such matchup data set ever assembled. AquaSat contains more than 600,000 matchups, covering 1984–2019, of ground-based total suspended sediment, dissolved organic carbon, chlorophyll a, and SDDSecchi disk depth measurements paired with spectral reflectance from Landsat 5, 7, and 8 collected within ±1 day of each other. To build AquaSat, we developed open source tools in R and Python and applied them to existing public data sets covering the contiguous United States, including the Water Quality Portal, LAGOS-NE, and the Landsat archive. In addition to publishing the data set, we are also publishing our full code architecture to facilitate expanding and improving AquaSat. We anticipate that this work will help make remote sensing of inland water accessible to more hydrologists, ecologists, and limnologists while facilitating novel data-driven approaches to monitoring and understanding critical water resources at large spatiotemporal scales.},
year = {2019}
}
@article{doi:10.1029/2018WR023333,
author = {Sun, Alexander Y. and Scanlon, Bridget R. and Zhang, Zizhan and Walling, David and Bhanja, Soumendra N. and Mukherjee, Abhijit and Zhong, Zhi},
title = {Combining Physically Based Modeling and Deep Learning for Fusing GRACE Satellite Data: Can We Learn From Mismatch?},
journal = {Water Resources Research},
volume = {55},
number = {2},
pages = {1179-1195},
keywords = {deep learning, GRACE, GLDAS, Unet, transfer learning, CNN},
doi = {10.1029/2018WR023333},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR023333},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR023333},
note = { 10.1029/2018WR023333},
abstract = {Abstract Global hydrological and land surface models are increasingly used for tracking terrestrial total water storage (TWS) dynamics, but the utility of existing models is hampered by conceptual and/or data uncertainties related to various underrepresented and unrepresented processes, such as groundwater storage. The gravity recovery and climate experiment (GRACE) satellite mission provided a valuable independent data source for tracking TWS at regional and continental scales. Strong interests exist in fusing GRACE data into global hydrological models to improve their predictive performance. Here we develop and apply deep convolutional neural network (CNN) models to learn the spatiotemporal patterns of mismatch between TWS anomalies (TWSA) derived from GRACE and those simulated by NOAH, a widely used land surface model. Once trained, our CNN models can be used to correct the NOAH-simulated TWSA without requiring GRACE data, potentially filling the data gap between GRACE and its follow-on mission, GRACE-FO. Our methodology is demonstrated over India, which has experienced significant groundwater depletion in recent decades that is nevertheless not being captured by the NOAH model. Results show that the CNN models significantly improve the match with GRACE TWSA, achieving a country-average correlation coefficient of 0.94 and Nash-Sutcliff efficient of 0.87, or 14\% and 52\% improvement, respectively, over the original NOAH TWSA. At the local scale, the learned mismatch pattern correlates well with the observed in situ groundwater storage anomaly data for most parts of India, suggesting that deep learning models effectively compensate for the missing groundwater component in NOAH for this study region.},
year = {2019}
}
@article{doi:10.1029/2019WR024892,
author = {Cho, Eunsang and Jacobs, Jennifer M. and Jia, Xinhua and Kraatz, Simon},
title = {Identifying Subsurface Drainage using Satellite Big Data and Machine Learning via Google Earth Engine},
journal = {Water Resources Research},
volume = {55},
number = {10},
pages = {8028-8045},
keywords = {land use and land cover change, subsurface drainage system, satellite big data, random forest machine learning, sustainable water management, flood forecasting},
doi = {10.1029/2019WR024892},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024892},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024892},
note = { 2019WR024892},
abstract = {Abstract Human-induced landscape changes affect hydrologic responses (e.g., floods) that can be detected from a suite of satellite and model data sets. Tapping these vast data sets using machine learning algorithms can produce critically important and accurate insights. In the Red River of the North Basin in the United States, agricultural subsurface drainage (SD; so-called tile drainage) systems have greatly increased since the late 1990s. Over this period, river flow in the Red River has markedly increased and 6 of 13 major floods during the past century have occurred in the past two decades. The impact of SD systems on river flow is elusive because there are surprisingly few SD records in the United States. In this study, Random Forest machine learning (RFML) classification method running on Google Earth Engine's cloud computing platform was able to capture SD within a field (30 m) and its expansion over time for a large watershed (>100,000 km2). The resulting RFML classifier drew from operational multiple satellites and model data sets (total 14 variables with 36 layers including vegetation, land cover, soil properties, and climate variables). The classifier identified soil properties and land surface temperature to be the strongest predictors of SD. The maps agreed well with SD permit records (overall accuracies of 76.9–87.0\%) and corresponded with subwatershed-level statistics (r = 0.77–0.96). It is expected that the maps produced with this data-intensive machine learning approach will help water resource managers to assess the hydrological impact from SD expansion and improve flood predictions in SD-dominated regions.},
year = {2019}
}
@article{doi:10.1029/2019WR024833,
author = {Kreyenberg, Philipp J. and Bauser, Hannes H. and Roth, Kurt},
title = {Velocity Field Estimation on Density-Driven Solute Transport With a Convolutional Neural Network},
journal = {Water Resources Research},
volume = {55},
number = {8},
pages = {7275-7293},
keywords = {Hele-Shaw cell experiment, density-driven active solute transport, convolutional neural network, velocity field estimation},
doi = {10.1029/2019WR024833},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024833},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024833},
note = { 10.1029/2019WR024833},
abstract = {Abstract Recent advances in machine learning open new opportunities to gain deeper insight into hydrological systems, where some relevant system quantities remain difficult to measure. We use deep learning methods trained on numerical simulations of the physical processes to explore the possibilities of closing the information gap of missing system quantities. As an illustrative example we study the estimation of velocity fields in numerical and laboratory experiments of density-driven solute transport. Using high-resolution observations of the solute concentration distribution, we demonstrate the capability of the method to structurally incorporate the representation of the physical processes. Velocity field estimation for synthetic data for both variable and uniform concentration boundary conditions showed equal results. This capability is remarkable because only the latter was employed for training the network. Applying the method to measured concentration distributions of density-driven solute transport in a Hele-Shaw cell makes the velocity field assessable in the experiment. This assessability of the velocity field even holds for regions with negligible solute concentration between the density fingers, where the velocity field is otherwise inaccessible.},
year = {2019}
}
@article{doi:10.1029/2018WR024461,
author = {Krapu, Christopher and Borsuk, Mark and Kumar, Mukesh},
title = {Gradient-Based Inverse Estimation for a Rainfall-Runoff Model},
journal = {Water Resources Research},
volume = {55},
number = {8},
pages = {6625-6639},
keywords = {Bayesian statistics, deep learning, optimization, rainfall-runoff modeling},
doi = {10.1029/2018WR024461},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024461},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024461},
note = { 2018WR024461},
abstract = {Abstract Recent advances in deep learning for neural networks with large numbers of parameters have been enabled by automatic differentiation, an algorithmic technique for calculating gradients of measures of model fit with respect to model parameters. Estimation of high-dimensional parameter sets is an important problem within the hydrological sciences. Here, we demonstrate the effectiveness of gradient-based estimation techniques for high-dimensional inverse estimation problems using a conceptual rainfall-runoff model. In particular, we compare the effectiveness of Hamiltonian Monte Carlo and automatic differentiation variational inference against two nongradient-dependent methods, random walk Metropolis and differential evolution Metropolis. We show that the former two techniques exhibit superior performance for inverse estimation of daily rainfall values and are much more computationally efficient on larger data sets in an experiment with synthetic data. We also present a case study evaluating the effectiveness of automatic differentiation variational inference for inverse estimation over 25 years of daily precipitation conditional on streamflow observations at three catchments and show that it is scalable to very high dimensional parameter spaces. The presented results highlight the power of combining hydrological process-based models with optimization techniques from deep learning for high-dimensional estimation problems.},
year = {2019}
}
@article{doi:10.1029/2019WR024902,
author = {Mao, Hanzi and Kathuria, Dhruva and Duffield, Nick and Mohanty, Binayak P.},
title = {Gap Filling of High-Resolution Soil Moisture for SMAP/Sentinel-1: A Two-Layer Machine Learning-Based Framework},
journal = {Water Resources Research},
volume = {55},
number = {8},
pages = {6986-7009},
keywords = {soil moisture, machine learning, multiresolution gap filling, SMAP satellite, SENTINEL-1 satellite, spatial/temporal machine learning},
doi = {10.1029/2019WR024902},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019WR024902},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019WR024902},
note = { 10.1029/2019WR024902},
abstract = {Abstract As the most recent 3-km soil moisture product from the Soil Moisture Active Passive (SMAP) mission, the SMAP/Sentinel-1 L2\_SM\_SP product has a unique capability to provide global-scale 3-km soil moisture estimates through the fusion of radar and radiometer microwave observations. The spatial and temporal availability of this high-resolution soil moisture product depends on concurrent radar and radiometer observations which is significantly restricted by the narrow swath and low revisit schedule of the Sentinel-1 radars. To address this issue, this paper presents a novel two-layer machine learning-based framework which predicts the brightness temperature and subsequently the soil moisture at gap areas. The proposed method is able to gap-fill soil moisture satisfactorily at areas where the radiometer observations are available while the radar observations are missing. We find that incorporating historical radar backscatter measurements (30-day average) into the machine learning framework boosts its predictive performance. The effectiveness of the two-layer framework is validated against regional holdout SMAP/Sentinel-1 3-km soil moisture estimates at four study areas with distinct climate regimes. Results indicate that our proposed method is able to reconstruct 3-km soil moisture at gap areas with high Pearson correlation coefficient (47\%/35\%/20\%/80\% improvement of mean R, at Arizona/Oklahoma/Iowa/Arkansas) and low unbiased Root Mean Square Error (20\%/10\%/7\%/26\% improvement of mean unbiased root mean square error) when compared to the SMAP 33-km soil moisture product. Additional validations against airborne data and in situ data from soil moisture networks are also satisfactory.},
year = {2019}
}
@article{doi:10.1029/2018WR024357,
author = {Araya, Samuel N. and Ghezzehei, Teamrat A.},
title = {Using Machine Learning for Prediction of Saturated Hydraulic Conductivity and Its Sensitivity to Soil Structural Perturbations},
journal = {Water Resources Research},
volume = {55},
number = {7},
pages = {5715-5737},
keywords = {soil hydraulic conductivity, machine learning, pedotransfer function, soil structure, bulk density, organic carbon},
doi = {10.1029/2018WR024357},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024357},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024357},
note = { 2018WR024357},
abstract = {Abstract Saturated hydraulic conductivity (Ks) is a fundamental soil property that regulates the fate of water in soils. Its measurement, however, is cumbersome and instead pedotransfer functions (PTFs) are routinely used to estimate it. Despite much progress over the years, the performance of current generic PTFs estimating Ks remains poor. Using machine learning, high-performance computing, and a large database of over 18,000 soils, we developed new PTFs to predict Ks. We compared the performances of four machine learning algorithms and different predictor sets. We evaluated the relative importance of soil properties in explaining Ks. PTF models based on boosted regression tree algorithm produced the best models with root-mean-squared log-transformed error in ranges of 0.4 to 0.3 (log10(cm/day)). The 10th percentile particle diameter (d10) was found to be the most important predictor followed by clay content, bulk density (ρb), and organic carbon content (C). The sensitivity of Ks to soil structure was investigated using ρb and C as proxies for soil structure. An inverse relationship was observed between ρb and Ks, with the highest sensitivity at around 1.8 g/cm3 for most textural classes. Soil C showed a complex relationship with Ks with an overall positive relation for fine-textured and midtextured soils but an inverse relation for coarse-textured soils. This study sought to maximize the extraction of information from a large database to develop generic machine learning-based PTFs for estimating Ks. Models developed here have been made publicly available and can be readily used to predict Ks.},
year = {2019}
}
@article{doi:10.1029/2018WR024136,
author = {Ling, Feng and Boyd, Doreen and Ge, Yong and Foody, Giles M. and Li, Xiaodong and Wang, Lihui and Zhang, Yihang and Shi, Lingfei and Shang, Cheng and Li, Xinyan and Du, Yun},
title = {Measuring River Wetted Width From Remotely Sensed Imagery at the Subpixel Scale With a Deep Convolutional Neural Network},
journal = {Water Resources Research},
volume = {55},
number = {7},
pages = {5631-5649},
keywords = {river wetted width, remote sensing, superresolution mapping, convolutional neural networks},
doi = {10.1029/2018WR024136},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024136},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024136},
note = { 2018WR024136},
abstract = {Abstract River wetted width (RWW) is an important variable in the study of river hydrological and biogeochemical processes. Presently, RWW is often measured from remotely sensed imagery, and the accuracy of RWW estimation is typically low when coarse spatial resolution imagery is used because river boundaries often run through pixels that represent a region that is a mixture of water and land. Thus, when conventional hard classification methods are used in the estimation of RWW, the mixed pixel problem can become a large source of error. To address this problem, this paper proposes a novel approach to measure RWW at the subpixel scale. Spectral unmixing is first applied to the imagery to obtain a water fraction image that indicates the proportional coverage of water in image pixels. A fine spatial resolution river map from which RWW may be estimated is then produced from the water fraction image by superresolution mapping (SRM). In the SRM analysis, a deep convolutional neural network is used to eliminate the negative effects of water fraction errors and reconstruct the geographical distribution of water. The proposed approach is assessed in two experiments, with the results demonstrating that the convolutional neural network-based SRM model can effectively estimate subpixel scale details of rivers and that the accuracy of RWW estimation is substantially higher than that obtained from the use of a conventional hard image classification. The improvement shows that the proposed method has great potential to derive more accurate RWW values from remotely sensed imagery.},
year = {2019}
}
@article{doi:10.1029/2018WR024301,
author = {Amaranto, A. and Munoz-Arriola, F. and Solomatine, D. P. and Corzo, G.},
title = {A Spatially Enhanced Data-Driven Multimodel to Improve Semiseasonal Groundwater Forecasts in the High Plains Aquifer, USA},
journal = {Water Resources Research},
volume = {55},
number = {7},
pages = {5941-5961},
keywords = {groundwater, artificial neural network, data-driven models, semi-seasonal forecast, irrigation},
doi = {10.1029/2018WR024301},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024301},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024301},
note = { 2018WR024301},
abstract = {Abstract The aim of this paper is to improve semiseasonal forecast of groundwater availability in response to climate variables, surface water availability, groundwater level variations, and human water management using a two-step data-driven modeling approach. First, we implement an ensemble of artificial neural networks (ANNs) for the 300 wells across the High Plains aquifer (USA). The modeling framework includes a method to choose the most relevant input variables and time lags; an assessment of the effect of exogenous variables on the predictive capabilities of models; and the estimation of the forecast skill based on the Nash-Sutcliffe efficiency (NSE) index, the normalized root mean square error, and the coefficient of determination (R2). Then, for the ANNs with low- accuracy, a MultiModel Combination (MuMoC) based on a hybrid of ANN and an instance-based learning method is applied. MuMoC uses forecasts from neighboring wells to improve the accuracy of ANNs. An exhaustive-search optimization algorithm is employed to select the best neighboring wells based on the cross correlation and predictive accuracy criteria. The results show high average ANN forecasting skills across the aquifer (average NSE > 0.9). Spatially distributed metrics of performance showed also higher error in areas of strong interaction between hydrometeorological forcings, irrigation intensity, and the aquifer. In those areas, the integration of the spatial information into MuMoC leads to an improvement of the model accuracy (NSE increased by 0.12), with peaks higher than 0.3 when the optimization objectives for selecting the neighbors were maximized.tT},
year = {2019}
}
@article{doi:10.1029/2018WR024480,
author = {Jiang, Shijie and Babovic, Vladan and Zheng, Yi and Xiong, Jianzhi},
title = {Advancing Opportunistic Sensing in Hydrology: A Novel Approach to Measuring Rainfall With Ordinary Surveillance Cameras},
journal = {Water Resources Research},
volume = {55},
number = {4},
pages = {3004-3027},
keywords = {rainfall gauging, opportunistic sensing, computer vision, crowdsourcing, rain-streak identification, image decomposition},
doi = {10.1029/2018WR024480},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024480},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024480},
note = { 2018WR024480},
abstract = {Abstract “Opportunistic sensing” represents an appealing idea for collecting unconventional data with broad spatial coverage and high resolution, but few studies have explored its feasibility in hydrology. This study develops a novel approach to measuring rainfall intensity in real-world conditions based on videos acquired by ordinary surveillance cameras. The proposed approach employs a convex optimization algorithm to effectively decompose a rainy image into two layers: a pure rain-streak layer and a rain-free background layer, where the rain streaks represent the motion blur of falling raindrops. Then, it estimates the instantaneous rainfall intensity via geometrical optics and photographic analyses. We investigated the effectiveness and robustness of our approach through synthetic numerical experiments and field tests. The major findings are as follows. First, the decomposition-based identification algorithm can effectively recognize rain streaks from complex backgrounds with many disturbances. Compared to existing algorithms that consider only the temporal changes in grayscale between frames, the new algorithm successfully prevents false identifications by considering the intrinsic visual properties of rain streaks. Second, the proposed approach demonstrates satisfactory estimation accuracy and is robust across a wide range of rainfall intensities. The proposed approach has a mean absolute percentage error of 21.8\%, which is significantly lower than those of existing approaches reported in the literature even though our approach was applied to a more complicated scene acquired using a lower-quality device. Overall, the proposed low-cost, high-accuracy approach to vision-based rain gauging significantly enhances the possibility of using existing surveillance camera networks to perform opportunistic hydrology sensing.},
year = {2019}
}
@article{doi:10.1029/2018WR023060,
author = {Ji, Luyan and Gong, Peng and Wang, Jie and Shi, Jiancheng and Zhu, Zhiliang},
title = {Construction of the 500-m Resolution Daily Global Surface Water Change Database (2001–2016)},
journal = {Water Resources Research},
volume = {54},
number = {12},
pages = {10,270-10,292},
keywords = {water, water change, daily water mapping, water time series, MODIS},
doi = {10.1029/2018WR023060},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR023060},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR023060},
note = { 2018WR023060},
abstract = {Abstract Surface water is the most dynamic land-cover type. Transitions between water and nonwater types (such as vegetation and ice) can happen momentarily. More frequent mapping is necessary to study the changing patterns of water. However, monitoring of long-term global water changes at high spatial resolution and in high temporal frequency is challenging. Here we report the generation of a daily global water map data set at 500-m resolution from 2001 to 2016 based on the daily reflectance time series from Moderate Resolution Imaging Spectroradiometer. Each single-date image is classified into three types: water, ice/snow, and land. Following temporal consistency check and spatial-temporal interpolation for missing data, we conducted a series of validation of the water data set. The producer's accuracy and user's accuracy are 94.61\% and 93.57\%, respectively, when checked with classification results derived from 30-m resolution Landsat images. Both the producer's accuracy and user's accuracy reached better than 90\% when compared with manually interpreted large-sized sample units (≥1,000 m × 1,000 m) collected in a previous global land cover mapping project. Generally, the global inland water area reaches its maximum (~3.80 × 106 km2) in September and minimum (~1.50 × 106 km2) in February during an annual cycle. Short-duration water bodies, sea level rise effects, different types of rice field use can be detected from the daily water maps. The size distribution of global water bodies is also discussed from the perspective of the number of water bodies and the corresponding water area. In addition, the daily water maps can precisely reflect water freezing and help correct water areas with inconsistent cloud flags in the MOD09GA quality assessment layer.},
year = {2018}
}
@article{doi:10.1029/2018WR023830,
author = {Tang, Guoqiang and Long, Di and Behrangi, Ali and Wang, Cunguang and Hong, Yang},
title = {Exploring Deep Neural Networks to Retrieve Rain and Snow in High Latitudes Using Multisensor and Reanalysis Data},
journal = {Water Resources Research},
volume = {54},
number = {10},
pages = {8253-8278},
keywords = {precipitation retrieval, spaceborne radar, deep neural network, high latitude},
doi = {10.1029/2018WR023830},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR023830},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR023830},
note = { 2018WR023830},
abstract = {Abstract Satellite remote sensing is able to provide information on global rain and snow, but challenges remain in accurate estimation of precipitation rates, particularly in snow retrieval. In this work, the deep neural network (DNN) is applied to estimate rain and snow rates in high latitudes. The reference data for DNN training are provided by two spaceborne radars onboard the Global Precipitation Measurement (GPM) Core Observatory and CloudSat. Passive microwave data from the GPM Microwave Imager (GMI), infrared data from MODerate resolution Imaging Spectroradiometer and environmental data from European Centre for Medium-Range Weather Forecasts are trained to the spaceborne radar-based reference precipitation. The DNN estimates are compared to data from the Goddard Profiling Algorithm (GPROF), which is used to retrieve passive microwave precipitation for the GPM mission. First, the DNN-based retrieval method performs well in both training and testing periods. Second, the DNN can reveal the advantages and disadvantages of different channels of GMI and MODerate resolution Imaging Spectroradiometer. Additionally, infrared and environmental data can improve precipitation estimation of the DNN, particularly for snowfall. Finally, based on the optimized DNN, rain and snow are estimated in 2017 from orbital GMI brightness temperatures and compared to ERA-Interim and Modern-Era Retrospective analysis for Research and Applications Version 2 reanalysis data. Evaluation results show that (1) the DNN can largely mitigate the underestimation of precipitation rates in high latitudes by GPROF; (2) the DNN-based snowfall estimates largely outperform those of GPROF; and (3) the spatial distributions of DNN-based precipitation are closer to reanalysis data. The method and assessment presented in this study could potentially contribute to the substantial improvement of satellite precipitation products in high latitudes.},
year = {2018}
}
@article{doi:10.1029/2018WR022643,
author = {Shen, Chaopeng},
title = {A Transdisciplinary Review of Deep Learning Research and Its Relevance for Water Resources Scientists},
journal = {Water Resources Research},
volume = {54},
number = {11},
pages = {8558-8593},
keywords = {deep learning, artificial intelligence, AI neuroscience, data mining, transformative},
doi = {10.1029/2018WR022643},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR022643},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR022643},
note = { 2018WR022643},
abstract = {Abstract Deep learning (DL), a new generation of artificial neural network research, has transformed industries, daily lives, and various scientific disciplines in recent years. DL represents significant progress in the ability of neural networks to automatically engineer problem-relevant features and capture highly complex data distributions. I argue that DL can help address several major new and old challenges facing research in water sciences such as interdisciplinarity, data discoverability, hydrologic scaling, equifinality, and needs for parameter regionalization. This review paper is intended to provide water resources scientists and hydrologists in particular with a simple technical overview, transdisciplinary progress update, and a source of inspiration about the relevance of DL to water. The review reveals that various physical and geoscientific disciplines have utilized DL to address data challenges, improve efficiency, and gain scientific insights. DL is especially suited for information extraction from image-like data and sequential data. Techniques and experiences presented in other disciplines are of high relevance to water research. Meanwhile, less noticed is that DL may also serve as a scientific exploratory tool. A new area termed AI neuroscience, where scientists interpret the decision process of deep networks and derive insights, has been born. This budding subdiscipline has demonstrated methods including correlation-based analysis, inversion of network-extracted features, reduced-order approximations by interpretable models, and attribution of network decisions to inputs. Moreover, DL can also use data to condition neurons that mimic problem-specific fundamental organizing units, thus revealing emergent behaviors of these units. Vast opportunities exist for DL to propel advances in water sciences.},
year = {2018}
}
@article{doi:10.1029/2018WR023205,
author = {Quilty, John and Adamowski, Jan and Boucher, Marie-Amélie},
title = {A Stochastic Data-Driven Ensemble Forecasting Framework for Water Resources: A Case Study Using Ensemble Members Derived From a Database of Deterministic Wavelet-Based Models},
journal = {Water Resources Research},
volume = {55},
number = {1},
pages = {175-202},
keywords = {ensemble forecasting, probabilistic forecasting, stochastic, input variable selection, data driven, wavelets},
doi = {10.1029/2018WR023205},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR023205},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR023205},
note = { 2018WR023205},
abstract = {Abstract In water resources applications (e.g., streamflow, rainfall-runoff, urban water demand [UWD], etc.), ensemble member selection and ensemble member weighting are two difficult yet important tasks in the development of ensemble forecasting systems. We propose and test a stochastic data-driven ensemble forecasting framework that uses archived deterministic forecasts as input and results in probabilistic water resources forecasts. In addition to input data and (ensemble) model output uncertainty, the proposed approach integrates both ensemble member selection and weighting uncertainties, using input variable selection and data-driven methods, respectively. Therefore, it does not require one to perform ensemble member selection and weighting separately. We applied the proposed forecasting framework to a previous real-world case study in Montreal, Canada, to forecast daily UWD at multiple lead times. Using wavelet-based forecasts as input data, we develop the Ensemble Wavelet-Stochastic Data-Driven Forecasting Framework, the first multiwavelet ensemble stochastic forecasting framework that produces probabilistic forecasts. For the considered case study, several variants of Ensemble Wavelet-Stochastic Data-Driven Forecasting Framework, produced using different input variable selection methods (partial correlation input selection and Edgeworth Approximations-based conditional mutual information) and data-driven models (multiple linear regression, extreme learning machines, and second-order Volterra series models), are shown to outperform wavelet- and nonwavelet-based benchmarks, especially during a heat wave (first time studied in the UWD forecasting literature).},
year = {2019}
}
@article{doi:10.1029/2018WR023354,
author = {Abbaszadeh, Peyman and Moradkhani, Hamid and Zhan, Xiwu},
title = {Downscaling SMAP Radiometer Soil Moisture Over the CONUS Using an Ensemble Learning Method},
journal = {Water Resources Research},
volume = {55},
number = {1},
pages = {324-344},
keywords = {soil moisture downscaling, SMAP, ensemble learning, CONUS},
doi = {10.1029/2018WR023354},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR023354},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR023354},
note = { 2018WR023354},
abstract = {Abstract Soil moisture plays a critical role in improving the weather and climate forecast and understanding terrestrial ecosystem processes. It is a key hydrologic variable in agricultural drought monitoring, flood forecasting, and irrigation management as well. Satellite retrievals can provide unprecedented soil moisture information at the global scale; however, the products are generally provided at coarse resolutions (25–50 km2). This often hampers their use in regional or local studies. The National Aeronautics and Space Administration Soil Moisture Active Passive (SMAP) satellite mission was launched in January 2015 aiming to acquire soil moisture and freeze-thaw states over the globe with 2 to 3 days revisit frequency. This work presents a new framework based on an ensemble learning method while using atmospheric and geophysical information derived from remote-sensing and ground-based observations to downscale the level 3 daily composite version (L3\_SM\_P) of SMAP radiometer soil moisture over the Continental United States at 1-km spatial resolution. In the proposed method, a suite of remotely sensed and in situ data sets are used, including soil texture and topography data among other information. The downscaled product was validated against in situ soil moisture measurements collected from two high density validation sites and 300 sparse soil moisture networks throughout the Continental United States. On average, the unbiased Root Mean Square Error between the downscaled SMAP soil moisture data and in-situ soil moisture observations adequately met the SMAP soil moisture retrieval accuracy requirement of 0.04 m3/m3. In addition, other statistical measures, that is, Pearson correlation coefficient and bias, showed satisfactory results.},
year = {2019}
}
@article{doi:10.1029/2018WR024090,
author = {Pan, Baoxiang and Hsu, Kuolin and AghaKouchak, Amir and Sorooshian, Soroosh},
title = {Improving Precipitation Estimation Using Convolutional Neural Network},
journal = {Water Resources Research},
volume = {55},
number = {3},
pages = {2301-2321},
keywords = {deep learning, precipitation, downscaling},
doi = {10.1029/2018WR024090},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR024090},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR024090},
note = { 10.1029/2018WR024090},
abstract = {Abstract Precipitation process is generally considered to be poorly represented in numerical weather/climate models. Statistical downscaling (SD) methods, which relate precipitation with model resolved dynamics, often provide more accurate precipitation estimates compared to model's raw precipitation products. We introduce the convolutional neural network model to foster this aspect of SD for daily precipitation prediction. Specifically, we restrict the predictors to the variables that are directly resolved by discretizing the atmospheric dynamics equations. In this sense, our model works as an alternative to the existing precipitation-related parameterization schemes for numerical precipitation estimation. We train the model to learn precipitation-related dynamical features from the surrounding dynamical fields by optimizing a hierarchical set of spatial convolution kernels. We test the model at 14 geogrid points across the contiguous United States. Results show that provided with enough data, precipitation estimates from the convolutional neural network model outperform the reanalysis precipitation products, as well as SD products using linear regression, nearest neighbor, random forest, or fully connected deep neural network. Evaluation for the test set suggests that the improvements can be seamlessly transferred to numerical weather modeling for improving precipitation prediction. Based on the default network, we examine the impact of the network architectures on model performance. Also, we offer simple visualization and analyzing approaches to interpret the models and their results. Our study contributes to the following two aspects: First, we offer a novel approach to enhance numerical precipitation estimation; second, the proposed model provides important implications for improving precipitation-related parameterization schemes using a data-driven approach.},
year = {2019}
}
@article{doi:10.1029/2018WR023939,
author = {Koch, Julian and Stisen, Simon and Refsgaard, Jens C. and Ernstsen, Vibeke and Jakobsen, Peter R. and Højberg, Anker L.},
title = {Modeling Depth of the Redox Interface at High Resolution at National Scale Using Random Forest and Residual Gaussian Simulation},
journal = {Water Resources Research},
volume = {55},
number = {2},
pages = {1451-1469},
keywords = {Water Resource Managment, Nitrate, Redox Conditions, Machine Learning, Random Forest, Geostatistics},
doi = {10.1029/2018WR023939},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR023939},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018WR023939},
note = { 2018WR023939},
abstract = {Abstract The management of water resources needs robust methods to efficiently reduce nitrate loads. Knowledge on where natural denitrification takes place in the subsurface is thereby essential. Nitrate is naturally reduced in anoxic environments and high-resolution information of the redox interface, that is, the depth of the uppermost reduced zone is crucial to understand the variability of the denitrification potential. In this study we explore the opportunity to use random forest (RF) regression to model redox depth across Denmark at 100-m resolution based on ~13,000 boreholes as training data. We highlight the importance of expert knowledge to guide the RF model in areas where our conceptual understanding is not represented correctly in the training data set by addition of artificial observations. We apply random forest regression kriging in which sequential Gaussian simulation models the RF residuals. The RF model reaches a R2 score of 0.48 for an independent validation test. Including sequential Gaussian simulation honors observations through local conditioning, and the spread of 800 realizations can be utilized to map uncertainty. Emphasis is put on adequate handling of nonstationarities in variance and spatial correlation of the RF residuals. The RF residuals show no spatial correlation for large parts of the modeling domain, and a local variance scaling method is applied to account for the nonstationary variance. Moreover, we present and exemplify a framework where newly acquired field data can easily be integrated into random forest regression kriging to quickly update local models.},
year = {2019}
}


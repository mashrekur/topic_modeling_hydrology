{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd \n",
    "from gensim.models import LdaModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTopics = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "lda_model = LdaModel.load(f'trained_models/trained_lda_model_{nTopics}')\n",
    "\n",
    "# Load topic distributions\n",
    "topic_distributions = np.load(f'data/topic_distributions_{lda_model.num_topics}.npy')\n",
    "\n",
    "# Pull topics\n",
    "topics = lda_model.show_topics(formatted=False, num_topics=nTopics, num_words=20)\n",
    "\n",
    "# load raw corpus dataframe\n",
    "with open('data/raw_corpus.pkl', 'rb') as f:\n",
    "    corpus_df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all nans to zeros and all zeros to a very small number\n",
    "# topic_distributions = np.nan_to_num(topic_distributions)\n",
    "topic_distributions = np.where(topic_distributions == 0, 0.000001, topic_distributions)\n",
    "# topic_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(topic_distributions == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller_set = topic_distributions[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_df['Title'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define topic names\n",
    "# topic_names = [\n",
    "#     'Precip Variability & Extr',\n",
    "#     'Hydrogeochemistry',\n",
    "#     'Uncertainty',\n",
    "#     'Soil Moisture',\n",
    "#     'Statistical Hydrology',\n",
    "#     'Rainfall-Runoff',\n",
    "#     'Precip Observation',\n",
    "#     'Modeling & Calibration',\n",
    "#     'Water Management',\n",
    "#     'Snow Hydrology',\n",
    "#     'Streamflow Processes',\n",
    "#     'Water Quality',\n",
    "#     'Channel Flow',\n",
    "#     'Floods',\n",
    "#     'Sediment & Erosion',\n",
    "#     'Climate Change',\n",
    "#     'Subsurface Flow & Trans',\n",
    "#     'Scaling & Spatial Variabil',\n",
    "#     'Land Surface Fluxes',\n",
    "#     'Hydrogeology',\n",
    "#     'Human Interv & Eff',\n",
    "#     'Land Cover',\n",
    "#     'Systems Hydrology',\n",
    "#     'Modeling & Forecasting',\n",
    "#     'Groundwater'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define colors to associate with each topic\n",
    "# custom_colors = {\n",
    "#  'burlywood': '#DEB887',\n",
    "#  'chocolate': '#D2691E',\n",
    "#  'crimson': '#DC143C',\n",
    "#  'darkgreen': '#006400',\n",
    "#  'darkorange': '#FF8C00',\n",
    "#  'darkslategrey': '#2F4F4F',\n",
    "#  'deepskyblue': '#00BFFF',\n",
    "#  'dimgray': '#696969',\n",
    "#  'firebrick': '#B22222',\n",
    "#  'gold': '#FFD700',\n",
    "#  'goldenrod': '#DAA520',\n",
    "#  'lawngreen': '#7CFC00',\n",
    "#  'lightcoral': '#F08080',\n",
    "#  'lightpink': '#FFB6C1',\n",
    "#  'mediumvioletred': '#C71585',\n",
    "#  'orangered': '#FF4500',\n",
    "#  'orchid': '#DA70D6',\n",
    "#  'royalblue': '#4169E1',\n",
    "#  'slateblue': '#6A5ACD',\n",
    "#  'springgreen': '#00FF7F',\n",
    "#  'steelblue': '#4682B4',\n",
    "#  'teal': '#008080',\n",
    "#  'turquoise': '#40E0D0',\n",
    "#  'yellow': '#FFFF00',\n",
    "#  'blueviolet': '#8A2BE2',\n",
    "#  'yellowgreen': '#9ACD32'}\n",
    "\n",
    "# # turn into a list\n",
    "# colorlist = []\n",
    "# for i, color in enumerate(custom_colors.values()):\n",
    "#     colorlist.append(tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)))\n",
    "#     colorlist[i] = (colorlist[i][0] / 256, colorlist[i][1] / 256, colorlist[i][2] / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate JSD for all pairs of papers\n",
    "#the max force values (dist) are capped to 1000 later on\n",
    "def calc_KL_divergence(paper1,paper2):\n",
    "    return -np.nansum(paper1 * np.log(paper2/paper1))\n",
    "def jensen_shannon_distance(paper1,paper2):\n",
    "    M=0.5*(paper1+paper2)\n",
    "    D1=calc_KL_divergence(paper1,M)\n",
    "    D2=calc_KL_divergence(paper2,M)\n",
    "    JSDiv = 0.5*D1+0.5*D2\n",
    "    JSD = np.sqrt(JSDiv)\n",
    "    return JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate individual lists for nodes and links\n",
    "node_list = []\n",
    "link_list = []\n",
    "\n",
    "# dist_values = np.full([corpus_df.shape[0], corpus_df.shape[0]], np.nan)\n",
    "# dist_values = np.full([1000, 1000], -0.1)\n",
    "\n",
    "for p1, paper1 in enumerate(corpus_df[\"Title\"][:]):\n",
    "    grp = {\"group\" : np.argmax(topic_distributions[p1]), \"name\": paper1}\n",
    "    node_list.append(grp)\n",
    "    for p2, paper2 in enumerate(corpus_df[\"Title\"][p1:]):\n",
    "        if p1 == p2:\n",
    "            dist = 0\n",
    "        else:\n",
    "            #round to 2 decimal places and multiply by 10\n",
    "            JSD = jensen_shannon_distance(topic_distributions[p1], topic_distributions[p2])\n",
    "            dist = round(1/JSD, 2)\n",
    "#             dist = round(1/JSD, 2)\n",
    "#             if dist >= 0.1 and dist <= 10:\n",
    "            link = {\"source\": p1, \"target\": p2, \"value\": dist}\n",
    "            link_list.append(link)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array and save\n",
    "node_array = np.array(node_list)\n",
    "link_array = np.array(link_list)\n",
    "\n",
    "with open('node_array.npy', 'wb') as f:\n",
    "    np.save(f, node_array)\n",
    "with open('link_array.npy', 'wb') as f:\n",
    "    np.save(f, link_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the lists\n",
    "# with open(\"node_list_full20.txt\", \"wb\") as fp:\n",
    "#     pkl.dump(node_list, fp)\n",
    "# with open(\"link_list_full20.txt\", \"wb\") as fp:\n",
    "#     pkl.dump(link_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #initiate json file\n",
    "# json_prep = {\"links\":link_list, \"nodes\":node_list}\n",
    "# # json_prep = {\"links\":link_list}\n",
    "# #json does not recognize NumPy data types; defining own encoder\n",
    "# class NpEncoder(json.JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.integer):\n",
    "#             return int(obj)\n",
    "#         elif isinstance(obj, np.floating):\n",
    "#             return float(obj)\n",
    "#         elif isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         else:\n",
    "#             return super(NpEncoder, self).default(obj)\n",
    "\n",
    "# #dumping the data into json file\n",
    "# json_dump = json.dumps(json_prep, indent=1, sort_keys=True, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(json_prep['nodes']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(json_prep['links']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save output\n",
    "# filename_out = 'hiddenstories_full20.json'\n",
    "# json_out = open(filename_out,'w')\n",
    "# json_out.write(json_dump)\n",
    "# json_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
